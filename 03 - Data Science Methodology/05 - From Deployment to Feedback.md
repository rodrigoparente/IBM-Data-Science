# Deployment

 - While a data science model will provide an answer, the key to making the answer relevant and useful to address the initial question, involves getting the stakeholders familiar with the tool produced;
 - Once the model is evaluated and the data scientist is confident it will work, it is deployed and put to the ultimate test;
 - Depending on the purpose of the model, it may be rolled out to a limited group of users or in a test environment, to build up confidence in applying the outcome for use across the board.

**Case Study**

In preparation for solution deployment, the next step was to assimilate the knowledge for the business group who would be designing and managing the intervention program to reduce readmission risk. In this scenario, the business people translated the model results so that the clinical staff could understand how to identify high-risk patients and design suitable intervention actions. The goal, of course, was to reduce the likelihood that these patients would be readmitted within 30 days after discharge. During the business requirements stage, the Intervention Program Director and her team had wanted an application that would provide automated, near real-time risk assessments of congestive heart failure. It also had to be easy for clinical staff to use, and preferably through browser-based application on a tablet, that each staff member could carry around. This patient data was generated throughout the hospital stay. It would be automatically prepared in a format needed by the model and each patient would be scored near the time of discharge. Clinicians would then have the most up-to-date risk assessment for each patient, helping them to select which patients to target for intervention after discharge. As part of solution deployment, the Intervention team would develop and deliver training for the clinical staff. Also, processes for tracking and monitoring patients receiving the intervention would have to be developed in collaboration with IT developers and database administrators, so that the results could go through the feedback stage and the model could be refined over time. 

# Feedback

 - Once in play, feedback from the users will help to refine the model and assess it for performance and impact;
 - The value of the model will be dependent on successfully incorporating feedback and making adjustments for as long as the solution is required;
 - The feedback process is rooted in the notion that, the more you know, the more that you'll want to know.

**Study Case**

The plan for the feedback stage included these steps:

 1. The review process would be defined and put into place, with overall responsibility for measuring the results of a "flying to risk" model of the congestive heart failure risk population;
 2. Congestive heart failure patients receiving intervention would be tracked and their re-admission outcomes recorded;
 3. The intervention would then be measured to determine how effective it was in reducing re-admissions.

For ethical reasons, congestive heart failure patients would not be split into controlled and treatment groups. Instead, readmission rates would be compared before and after the implementation of the model to measure its impact. After the deployment and feedback stages, the impact of the intervention program on re-admission rates would be reviewed after the first year of its implementation. Then the model would be refined, based on all of the data compiled after model implementation and the knowledge gained throughout these stages.

# Storytelling

 - Storytelling is crucial for data analysts to effectively communicate their findings and make data understandable and compelling;
 - Humans naturally understand the world through stories, making storytelling an effective way to convey data and drive action;
 - It's essential to find a balance between telling a clear, simple story and conveying the complexities within the data;
 - The ability to communicate data through storytelling is a critical skill, often more valuable than technical skills alone;
 - Stories create an emotional connection, making the data more memorable and impactful, as evidenced by studies showing that stories are more likely to be remembered than raw data alone.

# Summary

 - Stakeholders, including the solution owner, marketing staff, application developers, and IT administration evaluate the model and contribute feedback;
 - During the Deployment stage, data scientists release the data model to a targeted group of stakeholders;
 - Stakeholder and user feedback help assess the model's performance and impact during the Feedback stage;
 - The model's value depends on iteration; that is, how successfully the data model incorporates user feedback.

# Glossary

| Term | Definition |
|------|------------|
| Cyclical methodology | An iterative approach to the data science process, where each stage informs and refines the subsequent stages | 
| Review process | The systematic assessment and evaluation of the data science model's performance and impact |
| Storytelling | Storytelling is the art of conveying your message, or ideas through a narrative structure that engages, entertains, and resonates with the audience |
